import os
import re
import json
from datetime import time
from datetime import datetime
from typing import List, Dict, Any

from openai import OpenAI
from dotenv import load_dotenv

from app.service.vector_service import VectorService
from app.service.time_service import TimeService
from app.common.regions import parse_timezone_from_input, REGION_NAME_MAP

load_dotenv()

class AgentService:
    """
    HW-day2 AgentService
    - RAG(VectorDB) + Function Calling(TimeService) í†µí•©
    """


    def __init__(
        self,
        vector_service: VectorService,
        time_service: TimeService,
    ):
        api_key = os.getenv("UPSTAGE_API_KEY")
        if not api_key:
            raise ValueError("UPSTAGE_API_KEY environment variable is required")

        self.client = OpenAI(
            api_key=api_key,
            base_url="https://api.upstage.ai/v1"
        )

        self.vector_service = vector_service
        self.time_service = time_service


    # =====================================================
    # Public Entry
    # =====================================================
    def process_query(self, query: str) -> Dict[str, Any]:

        # 1. ì§€ì—­/íƒ€ì„ì¡´ ì¶”ì¶œ
        timezone = parse_timezone_from_input(query)

        # ğŸ‘‰ ê²€ìƒ‰ìš© ì¿¼ë¦¬ ë³´ì •
        search_query = timezone if timezone else query

        # 2ï¸. RAG ê²€ìƒ‰
        search_results = self.vector_service.search(
            search_query,
            n_results=3
        )
        context = self._prepare_context(search_results)

        # 3. ì‹œê°„ ì¡°íšŒ
        time_info = self._get_time_info(query)
        local_dt = datetime.fromisoformat(time_info["datetime"])

        # 4. í†µí™” ê°€ëŠ¥ ì—¬ë¶€ íŒë‹¨
        decision = self._make_decision(context, local_dt)

        # 4ï¸. LLMì˜ ì„¤ëª… ì¶œë ¥
        response = self._generate_response(
            query=query,
            context=context,
            time_info=time_info,
            decision=decision
        )

        return {
            "ai_message": response
        }


    # =====================================================
    # Make Decision
    # =====================================================
    def _extract_time_range(self, text: str, label: str) -> tuple[time, time] | None:
        """
        ì˜ˆ: 'ê·¼ë¬´ ì‹œê°„ì€ 08:30ë¶€í„° 17:00ê¹Œì§€ì…ë‹ˆë‹¤'
        """
        pattern = rf"{label}.*?(\d{{1,2}}:\d{{2}}).*?(\d{{1,2}}:\d{{2}})"
        match = re.search(pattern, text)

        if not match:
            return None

        start = time.fromisoformat(match.group(1))
        end = time.fromisoformat(match.group(2))
        return start, end

    def _make_decision(self, context: str, local_dt: datetime) -> dict:
        work_range = self._extract_time_range(context, "ê·¼ë¬´ ì‹œê°„")
        lunch_range = self._extract_time_range(context, "ì ì‹¬ì‹œê°„")

        now = local_dt.time()

        # ê¸°ë³¸ê°’
        decision = {
            "available": False,
            "reason": "ê·¼ë¬´ ì‹œê°„ ì™¸ì…ë‹ˆë‹¤."
        }

        if not work_range:
            decision["reason"] = "ê·¼ë¬´ ì‹œê°„ ê·œì •ì„ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            return decision

        work_start, work_end = work_range

        if not (work_start <= now <= work_end):
            decision["reason"] = f"ê·¼ë¬´ ì‹œê°„({work_start.strftime('%H:%M')}~{work_end.strftime('%H:%M')})ì´ ì•„ë‹™ë‹ˆë‹¤."
            return decision

        if lunch_range:
            lunch_start, lunch_end = lunch_range
            if lunch_start <= now <= lunch_end:
                decision["reason"] = f"ì ì‹¬ì‹œê°„({lunch_start.strftime('%H:%M')}~{lunch_end.strftime('%H:%M')})ì…ë‹ˆë‹¤."
                return decision

        decision["available"] = True
        decision["reason"] = "ê·¼ë¬´ ì‹œê°„ ë‚´ì´ë©° ì ì‹¬ì‹œê°„ì´ ì•„ë‹™ë‹ˆë‹¤."
        return decision

    # =====================================================
    # RAG Context
    # =====================================================
    def _prepare_context(self, search_results: Dict[str, Any]) -> str:

        documents = search_results.get("documents", [])
        metadatas = search_results.get("metadatas", [])

        # ChromaëŠ” [[...]] êµ¬ì¡°
        if not documents or not documents[0]:
            return ""

        docs = documents[0]
        metas = metadatas[0] if metadatas else [{}] * len(docs)

        context_parts = []

        for doc, meta in zip(docs, metas):
            office = meta.get("office_name", "Unknown Office")
            country = meta.get("country", "")
            timezone = meta.get("timezone", "")

            context_parts.append(
                f"[{office} | {country} | {timezone}]\n{doc}"
            )

        return "\n\n".join(context_parts)


    # =====================================================
    # Time Tool
    # =====================================================
    def _get_time_info(self, query: str) -> Dict[str, Any] | None:

        timezone = parse_timezone_from_input(query)
        if not timezone:
            return None

        raw = self.time_service.get_current_time(timezone)
        data = json.loads(raw)

        region_name = REGION_NAME_MAP.get(timezone, timezone)

        return {
            "region": region_name,
            "timezone": timezone,
            "datetime": data["datetime"],
        }


    # =====================================================
    # LLM Generation
    # =====================================================
    def _generate_response(
        self,
        query: str,
        context: str,
        time_info: Dict[str, Any] | None,
        decision: Dict[str, Any],
    ) -> str:

        system_prompt = """
        ë„ˆëŠ” ê¸€ë¡œë²Œ ì§€ì‚¬ì˜ ê·¼ë¬´ ê·œì •ì„ ì„¤ëª…í•˜ëŠ” AI ë¹„ì„œë‹¤.

        ì¤‘ìš” ê·œì¹™:
        - í†µí™” ê°€ëŠ¥ ì—¬ë¶€ëŠ” ì´ë¯¸ ê²°ì •ë˜ì–´ ìˆë‹¤.
        - ë„ˆëŠ” ì ˆëŒ€ íŒë‹¨ì„ ë°”ê¾¸ê±°ë‚˜ ìƒˆë¡œ í•´ì„í•˜ì§€ ì•ŠëŠ”ë‹¤.
        - ì£¼ì–´ì§„ Decisionê³¼ Time ì •ë³´ë¥¼ ê·¸ëŒ€ë¡œ ì„¤ëª…ë§Œ í•œë‹¤.
        
        ë‹µë³€ í˜•ì‹ ê·œì¹™:
        1. ì²« ë¬¸ì¥ì€ ë°˜ë“œì‹œ "ë„¤, ê°€ëŠ¥í•©ë‹ˆë‹¤." ë˜ëŠ” "ì•„ë‹ˆìš”, ì§€ê¸ˆì€ ê³¤ë€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."ë¡œ ì‹œì‘í•œë‹¤.
        2. ë‘ ë²ˆì§¸ ë¬¸ì¥ì—ì„œ í˜„ì¬ ì§€ì—­ëª…(íƒ€ì„ì¡´ í¬í•¨)ê³¼ í˜„ì¬ ì‹œê°ì„ ë§í•œë‹¤.
        3. ì„¸ ë²ˆì§¸ ë¬¸ì¥ì—ì„œ ê·¼ë¬´ ê·œì • ë˜ëŠ” ì ì‹¬ì‹œê°„ ë“± ì´ìœ ë¥¼ ëª…í™•íˆ ì„¤ëª…í•œë‹¤.
        4. ë§ˆì§€ë§‰ ë¬¸ì¥ì—ì„œ ëŒ€ì•ˆ ì‹œê°„ì´ë‚˜ ê¶Œì¥ í–‰ë™ì„ ì œì‹œí•œë‹¤.
        5. ì¤„ë°”ê¿ˆ ì—†ì´ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ì‘ì„±í•œë‹¤.
        """


        time_section = (
            f"Current local time:\n"
            f"- Region: {time_info['region']}\n"
            f"- Timezone: {time_info['timezone']}\n"
            f"- Datetime: {time_info['datetime']}\n"
            if time_info else "Current local time: Unknown\n"
        )

        user_prompt = f"""
        Decision:
        - Contact Available: {decision['available']}
        - Reason: {decision['reason']}

        Office Rule Summary:
        {context}

        Current Time Information:
        - Region: {time_info['region']}
        - Timezone: {time_info['timezone']}
        - Datetime: {time_info['datetime']}

        ì‚¬ìš©ì ì§ˆë¬¸:
        {query}

        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê·œì¹™ì— ë§ëŠ” í•œêµ­ì–´ ë‹µë³€ì„ ìƒì„±í•˜ì„¸ìš”.
        """

        try:
            response = self.client.chat.completions.create(
                model="solar-pro2",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt},
                ],
                temperature=0.2,
                max_tokens=300,
            )
            return response.choices[0].message.content

        except Exception as e:
            return f"Error generating response: {str(e)}"

    from typing import List

    def add_knowledge_bulk(self, items: List[Any]):
        documents = []
        metadatas = []

        for item in items:
            documents.append(item.description)
            metadatas.append({
                "office_name": item.office_name,
                "timezone": item.timezone,
                "country": item.country,
            })

        self.vector_service.add_documents(documents, metadatas)

    def add_knowledge_batch(self, rules: List[Any]) -> Dict[str, Any]:
        documents = []
        metadatas = []

        for rule in rules:
            text = (
                f"{rule.office_name}ì˜ ê·¼ë¬´ ê·œì •:\n"
                f"{rule.description}"
            )

            metadata = {
                "office_name": rule.office_name,
                "timezone": rule.timezone,
                "country": rule.country,
            }

            documents.append(text)
            metadatas.append(metadata)

        self.vector_service.add_documents(
            documents=documents,
            metadatas=metadatas,
        )

        return {
            "status": "success",
            "count": len(documents),
        }


    def add_knowledge(
            self,
            documents: List[str],
            metadatas: List[Dict[str, Any]] | None = None,
    ):
        self.vector_service.add_documents(
            documents=documents,
            metadatas=metadatas,
        )
        return {"status": "success", "count": len(documents)}


    def get_knowledge_stats(self) -> Dict[str, Any]:
        return self.vector_service.get_collection_info()
